{"cells":[{"cell_type":"markdown","id":"0e0b56f5","metadata":{"id":"0e0b56f5"},"source":["# **Installing Required Packages**"]},{"cell_type":"code","execution_count":null,"id":"b4979f92","metadata":{"id":"b4979f92","outputId":"0c521514-e59d-4e53-97e8-9324a157c257"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (2.9.0)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (2.9.1)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.47.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n","Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.1)\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (21.0)\n","Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n","Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n","Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.26.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.10.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.8.1)\n","Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.7)\n","Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -harset-normalizer (c:\\programdata\\anaconda3\\lib\\site-packages)\n"]}],"source":["!pip install keras\n","! pip install tensorflow"]},{"cell_type":"markdown","id":"c6e230a3","metadata":{"id":"c6e230a3"},"source":["# **Importing Necessary Libraries**"]},{"cell_type":"code","execution_count":null,"id":"da1c7200","metadata":{"id":"da1c7200"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.io import loadmat\n","import os\n","import sys\n","import seaborn\n","from sklearn.preprocessing import MultiLabelBinarizer\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras_preprocessing.sequence import pad_sequences\n","from keras import backend\n","backend.set_image_data_format('channels_last')\n","from sklearn.ensemble import RandomForestClassifier\n","import pickle"]},{"cell_type":"markdown","id":"c43fdc06","metadata":{"id":"c43fdc06"},"source":["# **Helper Functions to run the code**"]},{"cell_type":"markdown","id":"1104e58e","metadata":{"id":"1104e58e"},"source":["### Function to load the ECG data from .hea and .wav files"]},{"cell_type":"code","execution_count":null,"id":"412e5a2c","metadata":{"id":"412e5a2c"},"outputs":[],"source":["def load_data(data_path): \n","    data, sex, age, diagnosis, pescription, history, surgery, wave_length=[],[],[],[],[],[],[],[]\n","    for subdirectories, directories, files in sorted(os.walk(data_path)): #iterating through all the data files\n","        for file_name in files:\n","            file_path = subdirectories + os.sep + file_name\n","            if file_name.endswith(\".mat\"):   #reading the matlab files\n","                x=loadmat(file_path)\n","                y = (x['val'])\n","                y= pad_sequences(y, maxlen=5000, truncating='post',padding=\"post\") #truncating upto first 5000 datapoints\n","                z=[]\n","                for i in range(12):\n","                  z.append((np.asarray(y[i])))\n","                data.append(np.asarray(z))\n","            elif file_name.endswith(\".hea\"):   #iterating through the header files\n","                with open(file_path,'r') as f:\n","                    header_file_data=f.readlines()  #reading a header file\n","                length = header_file_data[0].split() #splitting the header files first line data word by word\n","                wave_length.append(length[3]) #choosing the 4th word( readoing wave length)\n","                sex.append(header_file_data[14][7:-1]) #saving the sex of patients in a list  \n","                age.append(header_file_data[13][7:-1])  #saving the age of patients in a list\n","                diagnosis.append(header_file_data[15][6:-1]) #saving the diagnosis of patients in a list\n","                pescription.append(header_file_data[16][6:-1]) #saving the pescription of patients in a list\n","                history.append(header_file_data[17][6:-1]) #saving the history of patients in a list\n","                surgery.append(header_file_data[16][6:-1]) #saving the surgery records of patients in a list\n","    data=np.asarray(data)\n","    return data, wave_length, diagnosis , pescription, history, surgery, sex, age"]},{"cell_type":"markdown","id":"0e3c6c2e","metadata":{"id":"0e3c6c2e"},"source":["### Function to encode the demographical data. I.e. Age,sex, etc."]},{"cell_type":"code","execution_count":null,"id":"1e1a1fe8","metadata":{"id":"1e1a1fe8"},"outputs":[],"source":["def demographical_data_encoding(sex,age):\n","  for i in range(len(sex)):\n","    if sex[i]==\"Male\" or sex[i]==\"M\":   #assigns 1 to male\n","      sex[i]=1\n","    elif sex[i]==\"Female\" or sex[i]==\"F\":   #assigns 0 to female\n","      sex[i]=0\n","    elif sex[i]==\"NaN\":   #assigns 2 where gender has NaN value\n","      sex[i]=2\n","  sex = np.asarray(sex)\n","\n","  rep=max(set(age), key = age.count) #returns the most occuring age in dataset\n","  for i in range(len(age)):   #assigns most occuring age to patient whose age is NAN \n","    if age[i]==\"NaN\":\n","      age[i]=rep\n","  for j in range(len(age)):   #converts age to type int\n","    age[j]=int(age[j])\n","  age = np.asarray(age)\n","\n","  for i in range(len(pescription)):\n","    if pescription[i]==\"Unknown\" or pescription[i]==\" \":\n","      pescription[i]=0\n","  pescription = np.asarray(pescription)\n","\n","  for i in range(len(history)):\n","    if history[i]==\"Unknown\" or history[i]==\" \":\n","      history[i]=0\n","  history = np.asarray(history)\n","\n","  for i in range(len(surgery)):\n","    if surgery[i]==\"Unknown\" or surgery[i]==\" \":\n","      surgery[i]=0\n","  surgery = np.asarray(surgery)\n","  return sex, age , pescription, history, surgery"]},{"cell_type":"markdown","id":"59023c7e","metadata":{"id":"59023c7e"},"source":["### Renet-50 Model Construction"]},{"cell_type":"markdown","id":"16313681","metadata":{"id":"16313681"},"source":["https://machinelearningknowledge.ai/keras-implementation-of-resnet-50-architecture-from-scratch/"]},{"cell_type":"code","execution_count":null,"id":"03a03d14","metadata":{"id":"03a03d14"},"outputs":[],"source":["def id_block(X,F1,F2,F3):\n","  X_copy=X\n","  #first convolutional layer\n","  X=keras.layers.Conv1D(filters=F1,kernel_size=1,strides=1,padding='valid')(X)\n","  X = keras.layers.BatchNormalization()(X)\n","  X = keras.layers.Activation('relu')(X)\n","  #second convolutional layer\n","  X=keras.layers.Conv1D(filters=F2,kernel_size=3,strides=1,padding='same')(X)\n","  X = keras.layers.BatchNormalization()(X)\n","  X = keras.layers.Activation('relu')(X)\n","  #third convolutional layer\n","  X=keras.layers.Conv1D(filters=F3,kernel_size=1,strides=1,padding='valid')(X)\n","  X = keras.layers.BatchNormalization()(X)\n","  #Adding original value of X to the obtained X\n","  X=keras.layers.Add()([X,X_copy])\n","  X=keras.layers.Activation('relu')(X)\n","\n","  return X   "]},{"cell_type":"code","execution_count":null,"id":"18c3a939","metadata":{"id":"18c3a939"},"outputs":[],"source":["def conv_block(X,F1,F2,F3):\n","  X_copy=X\n","  #first convolutional layer\n","  X=keras.layers.Conv1D(filters=F1,kernel_size=1,strides=2,padding='valid')(X)\n","  X = keras.layers.BatchNormalization()(X)\n","  X = keras.layers.Activation('relu')(X)\n","  #second convolutional layer\n","  X=keras.layers.Conv1D(filters=F2,kernel_size=3,strides=1,padding='same')(X)\n","  X = keras.layers.BatchNormalization()(X)\n","  X = keras.layers.Activation('relu')(X)\n","  #third convolutional layer\n","  X=keras.layers.Conv1D(filters=F3,kernel_size=1,strides=1,padding='valid')(X)\n","  X = keras.layers.BatchNormalization()(X)\n","  #direct path\n","  X_copy=keras.layers.Conv1D(filters=F3,kernel_size=1,strides=2,padding='valid')(X_copy)\n","  X_copy = keras.layers.BatchNormalization()(X_copy)\n","  #Adding original value of X to the obtained X\n","  X=keras.layers.Add()([X,X_copy])\n","  X=keras.layers.Activation('relu')(X)\n","\n","  return X"]},{"cell_type":"code","execution_count":null,"id":"534c5bb9","metadata":{"id":"534c5bb9"},"outputs":[],"source":["def RESNET_50(a):\n","    input_shape = a\n","    input_layer = keras.layers.Input(input_shape)\n","\n","    X=keras.layers.ZeroPadding1D(3)(input_layer)\n","\n","    X=keras.layers.Conv1D(filters=64,kernel_size=7,strides=2)(X)\n","    X=keras.layers.BatchNormalization()(X)\n","    X=keras.layers.Activation('relu')(X)\n","    X=keras.layers.MaxPooling1D(pool_size=1,strides=2)(X)\n","\n","    X=conv_block(X,64,64,256)\n","    X=id_block(X,64,64,256)\n","    X=id_block(X,64,64,256)\n","\n","    X=conv_block(X,128,128,512)\n","    X=id_block(X,128,128,512)\n","    X=id_block(X,128,128,512)\n","    X=id_block(X,128,128,512)\n","\n","    X=conv_block(X,256,256,1024)\n","    X=id_block(X,256,256,1024)\n","    X=id_block(X,256,256,1024)\n","    X=id_block(X,256,256,1024)\n","    X=id_block(X,256,256,1024)\n","    X=id_block(X,256,256,1024)\n","\n","    X=conv_block(X,512,512,2048)\n","    X=id_block(X,512,512,2048)\n","    X=id_block(X,512,512,2048)\n","\n","    X=keras.layers.AveragePooling1D(pool_size=2,padding='same')(X)\n","    X = keras.layers.Flatten()(X)\n","    X = keras.layers.Dense(28,activation='softmax')(X)\n","\n","    model = keras.models.Model(inputs=input_layer, outputs=X)\n","\n","    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=[tf.keras.metrics.BinaryAccuracy(\n","        name='accuracy', dtype=None, threshold=0.5), tf.keras.metrics.AUC(\n","        num_thresholds=200,\n","        curve=\"ROC\",\n","        summation_method=\"interpolation\",\n","        name=\"AUC\")])\n","\n","    return model"]},{"cell_type":"markdown","id":"681d47c4","metadata":{"id":"681d47c4"},"source":["### Function to combine data with demographical features"]},{"cell_type":"code","execution_count":null,"id":"943a23dc","metadata":{"id":"943a23dc"},"outputs":[],"source":["def data_append_demographics(data,age,sex):\n","    for i in range(len(data)):     \n","      for j in range(12):\n","        data[i][j].append(sex[i])\n","        data[i][j].append(age[i])\n","    return data"]},{"cell_type":"markdown","id":"b50be45b","metadata":{"id":"b50be45b"},"source":["### Seperating multi-labelled diagnosis and converting them to type int"]},{"cell_type":"code","execution_count":null,"id":"51693d5e","metadata":{"id":"51693d5e"},"outputs":[],"source":["def multi_labels_encoding(diagnosis):\n","    diagnosis_labels=[]           \n","    for i in range(len(diagnosis)):\n","      integers = [int(j) for j in diagnosis[i].split(',')]   #splitting where multilabelled data is present \n","      diagnosis_labels.append(integers)\n","    return diagnosis_labels"]},{"cell_type":"markdown","id":"e9fcfbe3","metadata":{"id":"e9fcfbe3"},"source":["### Function to convert 2D data into a numpy array"]},{"cell_type":"code","execution_count":null,"id":"0daf170c","metadata":{"id":"0daf170c"},"outputs":[],"source":["def list_to_array(data):\n","    feature_vector=[]                           #converting data to numpy array\n","    for i in range(len(data)):\n","      leads=[]\n","      for j in range(12):\n","        leads.append(np.asarray(data[i][j]))\n","      feature_vector.append(leads)\n","    feature_vector=np.asarray(feature_vector)\n","    return feature_vector"]},{"cell_type":"markdown","id":"366aad15","metadata":{"id":"366aad15"},"source":["### Function to remove unscored labels from dataset"]},{"cell_type":"code","execution_count":null,"id":"6d224ace","metadata":{"id":"6d224ace"},"outputs":[],"source":["def Remove_unscored_labels(diagnosis_labels,diseases):\n","    for i in range(len(diagnosis_labels)): \n","      for j in range(len(diagnosis_labels[i])):\n","        for k in range(len(diseases)):\n","          if(diagnosis_labels[i][j] == diseases[k]):\n","            diagnosis_labels[i][j]=0\n","    return diagnosis_labels"]},{"cell_type":"markdown","id":"bd7ded9f","metadata":{"id":"bd7ded9f"},"source":["### Function to form multi class labels"]},{"cell_type":"code","execution_count":null,"id":"66c7bbbd","metadata":{"id":"66c7bbbd"},"outputs":[],"source":["def multi_class_labels(diagnosis_labels,scored_labels):    \n","    final_labels=[]\n","    for a in range(len(diagnosis_labels)):\n","      temp=[0]*len(scored_labels)\n","      for b in range(len(diagnosis_labels[a])):\n","        for c in range(len(scored_labels)):\n","          if(diagnosis_labels[a][b] == scored_labels[c]):\n","            temp[c]=1\n","      final_labels.append(temp)\n","    final_labels=np.asarray(final_labels)\n","    return final_labels"]},{"cell_type":"markdown","id":"a4240f38","metadata":{"id":"a4240f38"},"source":["### Function to check the frequency of labels in the data"]},{"cell_type":"code","execution_count":null,"id":"9ce9716d","metadata":{"id":"9ce9716d"},"outputs":[],"source":["def check_label_freq(final_labels,scored_labels):\n","    temp=[0]*len(scored_labels)\n","    for i in range(len(final_labels)):\n","      for j in range(len(final_labels[i])):\n","        if final_labels[i][j]==1:\n","          temp[j]=temp[j]+1 \n","    return temp"]},{"cell_type":"markdown","id":"f08b2425","metadata":{"id":"f08b2425"},"source":["### Function to find unique labels in dataset"]},{"cell_type":"code","execution_count":null,"id":"defc4028","metadata":{"id":"defc4028"},"outputs":[],"source":["def unique_in_dataset(diagnosis_labels):\n","    unique_elements=[]\n","    for a in diagnosis_labels:\n","      for b in a: \n","        if b not in unique_elements: \n","            unique_elements.append(b)\n","    return unique_elements"]},{"cell_type":"markdown","id":"a3e65c2d","metadata":{"id":"a3e65c2d"},"source":["### Function to calculate the label weights"]},{"cell_type":"code","execution_count":null,"id":"4051aa50","metadata":{"id":"4051aa50"},"outputs":[],"source":["def calculating_class_weights(y_true):\n","    number_dim = np.shape(y_true)[1]\n","    weights = np.empty([number_dim, 2])\n","    for i in range(number_dim):\n","        weights[i] = compute_class_weight('balanced', [0.,1.], y_true[:, i])\n","    return weights"]},{"cell_type":"markdown","id":"b5d20f52","metadata":{"id":"b5d20f52"},"source":["### Function to Filter Noise From the data"]},{"cell_type":"markdown","id":"eafcc14c","metadata":{"id":"eafcc14c"},"source":["https://stackoverflow.com/questions/25191620/creating-lowpass-filter-in-scipy-understanding-methods-and-units"]},{"cell_type":"code","execution_count":null,"id":"0e3e7ac9","metadata":{"id":"0e3e7ac9"},"outputs":[],"source":["def butter_lowpass(cutoff,fs,order=5):\n","  nyq=0.5*fs\n","  normal_cutoff=cutoff/nyq\n","  b,a=butter(order,normal_cutoff,btype='low',analog=False)\n","  return b,a\n","def butter_lowpass_filter(data,cutoff,fs,order=5):\n","  b,a=butter_lowpass(cutoff,fs,order=order)\n","  y=lfilter(b,a,data)\n","  return y"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"supporting_functions.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}